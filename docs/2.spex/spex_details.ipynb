{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional topics\n",
    "\n",
    "Want to learn more about the literature on deriving thresholds on PET scan data in Alzheimer's disease? Want to know about how to derive your own simulated data to test the spatial extent module with different distributions? You've come to the right place!\n",
    "\n",
    "## Creating Gaussian simulated data\n",
    "\n",
    "### Inspiration from realistic data\n",
    "\n",
    "As you saw in the tutorial of the {ref}`spex module <2.spex/spex_module:Practice data>`, I generated random data to be used in the module. The goal was to mimic as close as possible what one could reasonable expect to see in a dataset with tau-PET data, but at the same time making sure `sihnpy` could derive thresholds relatively easily **AND** that I could showcase potential issues with the data.\n",
    "\n",
    "As I describe briefly in my {ref}`short introduction to GMM<2.spex/spex_module:Introduction to Gaussian mixture modelling (GMM)>`, tau-PET data in the Alzheimer's disease spectrum can usually be described as a **bimodal** distribution, where there is a large group of individuals with *low* PET SUVR and a small group with *high* PET SUVR. As the disease progress from normal cognition to diagnosed Alzheimer's disease, individuals will usually progress from *low* to *high*. So we know that to generate random data, we will need to generate data from a *low* and a *high* distribution.\n",
    "\n",
    "In Python, we can do this relatively easily if we have the **mean** and **standard deviation** for both the *low* and *high* distribution. So how do we choose that? At the time of developping `sihnpy`, and in the paper in which we use this methodology,[^Stonge_2023] we were working with data from the [Alzheimer's disease neuroimaging initiative (ADNI)](https://adni.loni.usc.edu/), one of the largest repository of open data on Alzheimer's disease, including a lot of amyloid- and tau-PET scans. In this dataset, we have participants that are at very low risk of progressing to Alzheimer's disease (participants who are cognitively unimpaired, with no discernable amounts of amyloid pathology) and participants who have already progressed to Alzheimer's disease (participants meeting the diagnostic criteria and with a lot of amyloid pathology). In `sihnpy`, the simulated data was created by slightly modifying the mean and standard deviation of these two groups of participants from ADNI. This information is actually available to all using `sihnpy` when using the `datasets` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_negative</th>\n",
       "      <th>sd_negative</th>\n",
       "      <th>mean_positive</th>\n",
       "      <th>sd_positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CTX_LH_ENTORHINAL_SUVR</th>\n",
       "      <td>1.119</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.578</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_RH_ENTORHINAL_SUVR</th>\n",
       "      <td>1.122</td>\n",
       "      <td>0.099</td>\n",
       "      <td>1.582</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_LH_AMYGDALA_SUVR</th>\n",
       "      <td>1.185</td>\n",
       "      <td>0.112</td>\n",
       "      <td>1.642</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_RH_AMYGDALA_SUVR</th>\n",
       "      <td>1.187</td>\n",
       "      <td>0.107</td>\n",
       "      <td>1.632</td>\n",
       "      <td>0.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_LH_FUSIFORM_SUVR</th>\n",
       "      <td>1.185</td>\n",
       "      <td>0.116</td>\n",
       "      <td>1.690</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_RH_FUSIFORM_SUVR</th>\n",
       "      <td>1.175</td>\n",
       "      <td>0.078</td>\n",
       "      <td>1.665</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_LH_PARAHIPPOCAMPAL_SUVR</th>\n",
       "      <td>1.097</td>\n",
       "      <td>0.095</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_RH_PARAHIPPOCAMPAL_SUVR</th>\n",
       "      <td>1.091</td>\n",
       "      <td>0.079</td>\n",
       "      <td>1.442</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_LH_INFERIORTEMPORAL_SUVR</th>\n",
       "      <td>1.199</td>\n",
       "      <td>0.132</td>\n",
       "      <td>1.799</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_RH_INFERIORTEMPORAL_SUVR</th>\n",
       "      <td>1.190</td>\n",
       "      <td>0.078</td>\n",
       "      <td>1.774</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_LH_MIDDLETEMPORAL_SUVR</th>\n",
       "      <td>1.161</td>\n",
       "      <td>0.130</td>\n",
       "      <td>1.671</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_RH_MIDDLETEMPORAL_SUVR</th>\n",
       "      <td>1.162</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1.674</td>\n",
       "      <td>0.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_LH_PRECENTRAL_SUVR</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.139</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_RH_PRECENTRAL_SUVR</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.073</td>\n",
       "      <td>1.133</td>\n",
       "      <td>0.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_LH_POSTCENTRAL_SUVR</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.074</td>\n",
       "      <td>1.084</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTX_RH_POSTCENTRAL_SUVR</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.074</td>\n",
       "      <td>1.091</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean_negative  sd_negative  mean_positive  \\\n",
       "region                                                                    \n",
       "CTX_LH_ENTORHINAL_SUVR                1.119        0.110          1.578   \n",
       "CTX_RH_ENTORHINAL_SUVR                1.122        0.099          1.582   \n",
       "CTX_LH_AMYGDALA_SUVR                  1.185        0.112          1.642   \n",
       "CTX_RH_AMYGDALA_SUVR                  1.187        0.107          1.632   \n",
       "CTX_LH_FUSIFORM_SUVR                  1.185        0.116          1.690   \n",
       "CTX_RH_FUSIFORM_SUVR                  1.175        0.078          1.665   \n",
       "CTX_LH_PARAHIPPOCAMPAL_SUVR           1.097        0.095          1.450   \n",
       "CTX_RH_PARAHIPPOCAMPAL_SUVR           1.091        0.079          1.442   \n",
       "CTX_LH_INFERIORTEMPORAL_SUVR          1.199        0.132          1.799   \n",
       "CTX_RH_INFERIORTEMPORAL_SUVR          1.190        0.078          1.774   \n",
       "CTX_LH_MIDDLETEMPORAL_SUVR            1.161        0.130          1.671   \n",
       "CTX_RH_MIDDLETEMPORAL_SUVR            1.162        0.077          1.674   \n",
       "CTX_LH_PRECENTRAL_SUVR                0.997        0.070          1.139   \n",
       "CTX_RH_PRECENTRAL_SUVR                0.995        0.073          1.133   \n",
       "CTX_LH_POSTCENTRAL_SUVR               0.972        0.074          1.084   \n",
       "CTX_RH_POSTCENTRAL_SUVR               0.971        0.074          1.091   \n",
       "\n",
       "                              sd_positive  \n",
       "region                                     \n",
       "CTX_LH_ENTORHINAL_SUVR              0.321  \n",
       "CTX_RH_ENTORHINAL_SUVR              0.300  \n",
       "CTX_LH_AMYGDALA_SUVR                0.299  \n",
       "CTX_RH_AMYGDALA_SUVR                0.272  \n",
       "CTX_LH_FUSIFORM_SUVR                0.506  \n",
       "CTX_RH_FUSIFORM_SUVR                0.485  \n",
       "CTX_LH_PARAHIPPOCAMPAL_SUVR         0.292  \n",
       "CTX_RH_PARAHIPPOCAMPAL_SUVR         0.313  \n",
       "CTX_LH_INFERIORTEMPORAL_SUVR        0.548  \n",
       "CTX_RH_INFERIORTEMPORAL_SUVR        0.554  \n",
       "CTX_LH_MIDDLETEMPORAL_SUVR          0.523  \n",
       "CTX_RH_MIDDLETEMPORAL_SUVR          0.516  \n",
       "CTX_LH_PRECENTRAL_SUVR              0.264  \n",
       "CTX_RH_PRECENTRAL_SUVR              0.256  \n",
       "CTX_LH_POSTCENTRAL_SUVR             0.252  \n",
       "CTX_RH_POSTCENTRAL_SUVR             0.286  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sihnpy import datasets\n",
    "tau_data, regional_thresholds, regional_averages = datasets.pad_spex_input()\n",
    "regional_averages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are what was used to generate `sihnpy` data, with a few exceptions. The goal was simply to get \"realistic\" data.\n",
    "\n",
    "### Generating randomized data\n",
    "\n",
    "From there, we have another choice to make. In the PREVENT-AD data, we have 308 participants in the Open Dataset. We need to choose how many are going to be attributed a \"normal\" and how many are going to be attributed an \"abnormal\" value. This is really arbitrary, so feel free to modify the numbers as needed. I created a simple function that generates the randomized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def gen_random_population(mean1, sd1, size1, mean2, sd2, size2):\n",
    "    \"\"\"Generates random data mimicking tau-PET SUVR data, of the size of the PREVENT-AD Open\n",
    "    dataset, by pulling 308 sample data points from 2 randomly generated populations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean1 : float\n",
    "        Mean of the first distribution\n",
    "    sd1 : float\n",
    "        Standard deviation of the first distribution\n",
    "    size1 : int\n",
    "        Size of the first population\n",
    "    mean2 : float\n",
    "        Mean of the second distribution\n",
    "    sd2 : float\n",
    "        Standard deviation of the second distribution\n",
    "    size2 : int\n",
    "        Size of the second population\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array\n",
    "        Numpy array containing the 308 random data points; 100 AD, 208 CU\n",
    "    \"\"\"\n",
    "\n",
    "    #Create a random population based on CU and on AD. Concatenate\n",
    "    pop_sim_neg_data = np.random.choice(stats.norm.rvs(mean1, sd1, size1, random_state=667), 208)\n",
    "    pop_sim_pos_data = np.random.choice(stats.norm.rvs(mean2, sd2, size2, random_state=667), 100)\n",
    "\n",
    "    return np.concatenate((pop_sim_neg_data, pop_sim_pos_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's breakdown how this function is working. The core of the function is `scipy`'s `stats.norm.rvs` function, which generates random samples of participants based on a given mean, standard deviation and size. I forced the `random_state` to be constant here, so the generated data would remain the same throughout testing, but it is up to you to do the same or not.\n",
    "\n",
    "Then, once the random samples are generated, we use `numpy`'s `random.choice` to randomly choose data points of the dimension we want (so for us, we will arbitrarily say there are 100 participants with *high* SUVR values and 208 participants with *low* SUVR values). This size choice is a bit different then the one inside of `stats.norm.rvs`. In `stats.norm.rvs`, the size is **how many random samples it should create**, while the size in `np.random.choice` is how many samples numpy should keep.\n",
    "\n",
    "From the tests I did before generating the final data, it is usually better to give a very large number of samples to `stats.norm.rvs` (e.g., 10,000) so that it gives more variety and stability to the final values `numpy` chooses.\n",
    "\n",
    "Once you have that function, you can simply generate a `pandas.DataFrame` or a `dict` containing the random data. Here is the code I used for the data in `sihnpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTX_LH_ENTORHINAL_SUVR</th>\n",
       "      <th>CTX_RH_ENTORHINAL_SUVR</th>\n",
       "      <th>CTX_LH_AMYGDALA_SUVR</th>\n",
       "      <th>CTX_RH_AMYGDALA_SUVR</th>\n",
       "      <th>CTX_LH_FUSIFORM_SUVR</th>\n",
       "      <th>CTX_RH_FUSIFORM_SUVR</th>\n",
       "      <th>CTX_LH_PARAHIPPOCAMPAL_SUVR</th>\n",
       "      <th>CTX_RH_PARAHIPPOCAMPAL_SUVR</th>\n",
       "      <th>CTX_LH_INFERIORTEMPORAL_SUVR</th>\n",
       "      <th>CTX_RH_INFERIORTEMPORAL_SUVR</th>\n",
       "      <th>CTX_LH_MIDDLETEMPORAL_SUVR</th>\n",
       "      <th>CTX_RH_MIDDLETEMPORAL_SUVR</th>\n",
       "      <th>CTX_LH_PRECENTRAL_SUVR</th>\n",
       "      <th>CTX_RH_PRECENTRAL_SUVR</th>\n",
       "      <th>CTX_LH_POSTCENTRAL_SUVR</th>\n",
       "      <th>CTX_RH_POSTCENTRAL_SUVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.051291</td>\n",
       "      <td>1.079570</td>\n",
       "      <td>1.148615</td>\n",
       "      <td>1.387371</td>\n",
       "      <td>1.234989</td>\n",
       "      <td>1.222629</td>\n",
       "      <td>0.997319</td>\n",
       "      <td>1.238408</td>\n",
       "      <td>1.193029</td>\n",
       "      <td>1.189048</td>\n",
       "      <td>1.176353</td>\n",
       "      <td>1.068580</td>\n",
       "      <td>1.043006</td>\n",
       "      <td>1.193375</td>\n",
       "      <td>0.956099</td>\n",
       "      <td>1.303371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.261927</td>\n",
       "      <td>1.128798</td>\n",
       "      <td>1.108885</td>\n",
       "      <td>1.094912</td>\n",
       "      <td>1.169001</td>\n",
       "      <td>1.110779</td>\n",
       "      <td>1.032457</td>\n",
       "      <td>1.114748</td>\n",
       "      <td>1.313168</td>\n",
       "      <td>1.245361</td>\n",
       "      <td>1.130955</td>\n",
       "      <td>1.215578</td>\n",
       "      <td>1.070534</td>\n",
       "      <td>1.210303</td>\n",
       "      <td>0.735064</td>\n",
       "      <td>0.525758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.913342</td>\n",
       "      <td>1.232583</td>\n",
       "      <td>1.113257</td>\n",
       "      <td>1.125692</td>\n",
       "      <td>1.121716</td>\n",
       "      <td>1.122116</td>\n",
       "      <td>1.239292</td>\n",
       "      <td>1.101351</td>\n",
       "      <td>1.437924</td>\n",
       "      <td>1.237383</td>\n",
       "      <td>1.407009</td>\n",
       "      <td>1.041744</td>\n",
       "      <td>0.965578</td>\n",
       "      <td>1.205039</td>\n",
       "      <td>0.848469</td>\n",
       "      <td>1.489493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.244253</td>\n",
       "      <td>1.095530</td>\n",
       "      <td>1.273662</td>\n",
       "      <td>0.976596</td>\n",
       "      <td>1.240247</td>\n",
       "      <td>1.218630</td>\n",
       "      <td>0.968086</td>\n",
       "      <td>1.073787</td>\n",
       "      <td>1.289952</td>\n",
       "      <td>1.209346</td>\n",
       "      <td>0.961912</td>\n",
       "      <td>1.262703</td>\n",
       "      <td>1.073792</td>\n",
       "      <td>1.101692</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>1.112140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.157736</td>\n",
       "      <td>1.385124</td>\n",
       "      <td>1.044202</td>\n",
       "      <td>1.251263</td>\n",
       "      <td>1.036178</td>\n",
       "      <td>1.223966</td>\n",
       "      <td>1.228288</td>\n",
       "      <td>1.084805</td>\n",
       "      <td>1.398520</td>\n",
       "      <td>1.274703</td>\n",
       "      <td>1.215081</td>\n",
       "      <td>1.195192</td>\n",
       "      <td>0.922243</td>\n",
       "      <td>1.161125</td>\n",
       "      <td>1.106643</td>\n",
       "      <td>1.203184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1.780437</td>\n",
       "      <td>1.470793</td>\n",
       "      <td>1.810637</td>\n",
       "      <td>1.948906</td>\n",
       "      <td>2.205414</td>\n",
       "      <td>1.974782</td>\n",
       "      <td>1.251331</td>\n",
       "      <td>0.981840</td>\n",
       "      <td>2.141611</td>\n",
       "      <td>3.032395</td>\n",
       "      <td>1.702946</td>\n",
       "      <td>0.695836</td>\n",
       "      <td>1.218570</td>\n",
       "      <td>0.893558</td>\n",
       "      <td>0.557759</td>\n",
       "      <td>0.907017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1.737320</td>\n",
       "      <td>1.264792</td>\n",
       "      <td>0.968907</td>\n",
       "      <td>1.809377</td>\n",
       "      <td>1.337959</td>\n",
       "      <td>1.933215</td>\n",
       "      <td>1.777517</td>\n",
       "      <td>1.088886</td>\n",
       "      <td>1.668091</td>\n",
       "      <td>2.180018</td>\n",
       "      <td>1.428016</td>\n",
       "      <td>1.467454</td>\n",
       "      <td>1.083992</td>\n",
       "      <td>1.022499</td>\n",
       "      <td>1.463762</td>\n",
       "      <td>1.388066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1.317423</td>\n",
       "      <td>1.635983</td>\n",
       "      <td>1.068091</td>\n",
       "      <td>2.225916</td>\n",
       "      <td>1.712976</td>\n",
       "      <td>2.139381</td>\n",
       "      <td>1.617846</td>\n",
       "      <td>1.525750</td>\n",
       "      <td>1.128397</td>\n",
       "      <td>2.026166</td>\n",
       "      <td>0.426102</td>\n",
       "      <td>1.897636</td>\n",
       "      <td>1.108812</td>\n",
       "      <td>0.978606</td>\n",
       "      <td>1.017627</td>\n",
       "      <td>0.814425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1.624967</td>\n",
       "      <td>1.661325</td>\n",
       "      <td>1.087939</td>\n",
       "      <td>2.092671</td>\n",
       "      <td>1.889238</td>\n",
       "      <td>1.318229</td>\n",
       "      <td>0.871777</td>\n",
       "      <td>1.447002</td>\n",
       "      <td>2.302911</td>\n",
       "      <td>2.067462</td>\n",
       "      <td>1.571238</td>\n",
       "      <td>1.570629</td>\n",
       "      <td>1.119042</td>\n",
       "      <td>0.937101</td>\n",
       "      <td>1.239425</td>\n",
       "      <td>1.391649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1.501337</td>\n",
       "      <td>1.505711</td>\n",
       "      <td>1.827844</td>\n",
       "      <td>1.693427</td>\n",
       "      <td>1.009246</td>\n",
       "      <td>1.744448</td>\n",
       "      <td>1.819464</td>\n",
       "      <td>1.021790</td>\n",
       "      <td>1.739160</td>\n",
       "      <td>2.136250</td>\n",
       "      <td>2.126833</td>\n",
       "      <td>1.499619</td>\n",
       "      <td>1.087383</td>\n",
       "      <td>0.894159</td>\n",
       "      <td>1.469735</td>\n",
       "      <td>1.039196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CTX_LH_ENTORHINAL_SUVR  CTX_RH_ENTORHINAL_SUVR  CTX_LH_AMYGDALA_SUVR  \\\n",
       "0                  1.051291                1.079570              1.148615   \n",
       "1                  1.261927                1.128798              1.108885   \n",
       "2                  0.913342                1.232583              1.113257   \n",
       "3                  1.244253                1.095530              1.273662   \n",
       "4                  1.157736                1.385124              1.044202   \n",
       "..                      ...                     ...                   ...   \n",
       "303                1.780437                1.470793              1.810637   \n",
       "304                1.737320                1.264792              0.968907   \n",
       "305                1.317423                1.635983              1.068091   \n",
       "306                1.624967                1.661325              1.087939   \n",
       "307                1.501337                1.505711              1.827844   \n",
       "\n",
       "     CTX_RH_AMYGDALA_SUVR  CTX_LH_FUSIFORM_SUVR  CTX_RH_FUSIFORM_SUVR  \\\n",
       "0                1.387371              1.234989              1.222629   \n",
       "1                1.094912              1.169001              1.110779   \n",
       "2                1.125692              1.121716              1.122116   \n",
       "3                0.976596              1.240247              1.218630   \n",
       "4                1.251263              1.036178              1.223966   \n",
       "..                    ...                   ...                   ...   \n",
       "303              1.948906              2.205414              1.974782   \n",
       "304              1.809377              1.337959              1.933215   \n",
       "305              2.225916              1.712976              2.139381   \n",
       "306              2.092671              1.889238              1.318229   \n",
       "307              1.693427              1.009246              1.744448   \n",
       "\n",
       "     CTX_LH_PARAHIPPOCAMPAL_SUVR  CTX_RH_PARAHIPPOCAMPAL_SUVR  \\\n",
       "0                       0.997319                     1.238408   \n",
       "1                       1.032457                     1.114748   \n",
       "2                       1.239292                     1.101351   \n",
       "3                       0.968086                     1.073787   \n",
       "4                       1.228288                     1.084805   \n",
       "..                           ...                          ...   \n",
       "303                     1.251331                     0.981840   \n",
       "304                     1.777517                     1.088886   \n",
       "305                     1.617846                     1.525750   \n",
       "306                     0.871777                     1.447002   \n",
       "307                     1.819464                     1.021790   \n",
       "\n",
       "     CTX_LH_INFERIORTEMPORAL_SUVR  CTX_RH_INFERIORTEMPORAL_SUVR  \\\n",
       "0                        1.193029                      1.189048   \n",
       "1                        1.313168                      1.245361   \n",
       "2                        1.437924                      1.237383   \n",
       "3                        1.289952                      1.209346   \n",
       "4                        1.398520                      1.274703   \n",
       "..                            ...                           ...   \n",
       "303                      2.141611                      3.032395   \n",
       "304                      1.668091                      2.180018   \n",
       "305                      1.128397                      2.026166   \n",
       "306                      2.302911                      2.067462   \n",
       "307                      1.739160                      2.136250   \n",
       "\n",
       "     CTX_LH_MIDDLETEMPORAL_SUVR  CTX_RH_MIDDLETEMPORAL_SUVR  \\\n",
       "0                      1.176353                    1.068580   \n",
       "1                      1.130955                    1.215578   \n",
       "2                      1.407009                    1.041744   \n",
       "3                      0.961912                    1.262703   \n",
       "4                      1.215081                    1.195192   \n",
       "..                          ...                         ...   \n",
       "303                    1.702946                    0.695836   \n",
       "304                    1.428016                    1.467454   \n",
       "305                    0.426102                    1.897636   \n",
       "306                    1.571238                    1.570629   \n",
       "307                    2.126833                    1.499619   \n",
       "\n",
       "     CTX_LH_PRECENTRAL_SUVR  CTX_RH_PRECENTRAL_SUVR  CTX_LH_POSTCENTRAL_SUVR  \\\n",
       "0                  1.043006                1.193375                 0.956099   \n",
       "1                  1.070534                1.210303                 0.735064   \n",
       "2                  0.965578                1.205039                 0.848469   \n",
       "3                  1.073792                1.101692                 0.944882   \n",
       "4                  0.922243                1.161125                 1.106643   \n",
       "..                      ...                     ...                      ...   \n",
       "303                1.218570                0.893558                 0.557759   \n",
       "304                1.083992                1.022499                 1.463762   \n",
       "305                1.108812                0.978606                 1.017627   \n",
       "306                1.119042                0.937101                 1.239425   \n",
       "307                1.087383                0.894159                 1.469735   \n",
       "\n",
       "     CTX_RH_POSTCENTRAL_SUVR  \n",
       "0                   1.303371  \n",
       "1                   0.525758  \n",
       "2                   1.489493  \n",
       "3                   1.112140  \n",
       "4                   1.203184  \n",
       "..                       ...  \n",
       "303                 0.907017  \n",
       "304                 1.388066  \n",
       "305                 0.814425  \n",
       "306                 1.391649  \n",
       "307                 1.039196  \n",
       "\n",
       "[308 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dict_random_tau_data = {}\n",
    "\n",
    "dict_random_tau_data[\"CTX_LH_ENTORHINAL_SUVR\"] = gen_random_population(mean1=1.119, sd1=0.110, size1=10000, mean2=1.578, sd2=0.321, size2=10000)\n",
    "dict_random_tau_data[\"CTX_RH_ENTORHINAL_SUVR\"] = gen_random_population(mean1=1.122, sd1=0.099, size1=10000, mean2=1.582, sd2=0.300, size2=10000)\n",
    "dict_random_tau_data[\"CTX_LH_AMYGDALA_SUVR\"] = gen_random_population(mean1=1.125, sd1=0.112, size1=10000, mean2=1.642, sd2=0.299, size2=10000)\n",
    "dict_random_tau_data[\"CTX_RH_AMYGDALA_SUVR\"] = gen_random_population(mean1=1.127, sd1=0.107, size1=10000, mean2=1.632, sd2=0.272, size2=10000)\n",
    "dict_random_tau_data[\"CTX_LH_FUSIFORM_SUVR\"] = gen_random_population(mean1=1.185, sd1=0.112, size1=10000, mean2=1.690, sd2=0.506, size2=10000)\n",
    "dict_random_tau_data[\"CTX_RH_FUSIFORM_SUVR\"] = gen_random_population(mean1=1.175, sd1=0.078, size1=10000, mean2=1.665, sd2=0.485, size2=10000)\n",
    "dict_random_tau_data[\"CTX_LH_PARAHIPPOCAMPAL_SUVR\"] = gen_random_population(mean1=1.097, sd1=0.095, size1=10000, mean2=1.450, sd2=0.292, size2=10000)\n",
    "dict_random_tau_data[\"CTX_RH_PARAHIPPOCAMPAL_SUVR\"] = gen_random_population(mean1=1.091, sd1=0.079, size1=10000, mean2=1.442, sd2=0.313, size2=10000)\n",
    "dict_random_tau_data[\"CTX_LH_INFERIORTEMPORAL_SUVR\"] = gen_random_population(mean1=1.199, sd1=0.132, size1=10000, mean2=1.799, sd2=0.548, size2=10000)\n",
    "dict_random_tau_data[\"CTX_RH_INFERIORTEMPORAL_SUVR\"] = gen_random_population(mean1=1.190, sd1=0.078, size1=10000, mean2=1.774, sd2=0.554, size2=10000)\n",
    "dict_random_tau_data[\"CTX_LH_MIDDLETEMPORAL_SUVR\"] = gen_random_population(mean1=1.161, sd1=0.130, size1=10000, mean2=1.671, sd2=0.523, size2=10000)\n",
    "dict_random_tau_data[\"CTX_RH_MIDDLETEMPORAL_SUVR\"] = gen_random_population(mean1=1.162, sd1=0.077, size1=10000, mean2=1.674, sd2=0.516, size2=10000)\n",
    "dict_random_tau_data[\"CTX_LH_PRECENTRAL_SUVR\"] = gen_random_population(mean1=0.997, sd1=0.070, size1=10000, mean2=1.139, sd2=0.264, size2=10000)\n",
    "dict_random_tau_data[\"CTX_RH_PRECENTRAL_SUVR\"] = gen_random_population(mean1=1.200, sd1=0.045, size1=10000, mean2=0.995, sd2=0.074, size2=10000) #Mimics inverted distribution\n",
    "dict_random_tau_data[\"CTX_LH_POSTCENTRAL_SUVR\"] = gen_random_population(mean1=0.972, sd1=0.074, size1=10000, mean2=1.084, sd2=0.252, size2=10000)\n",
    "dict_random_tau_data[\"CTX_RH_POSTCENTRAL_SUVR\"] = gen_random_population(mean1=1.091, sd1=0.286, size1=10000, mean2=1.091, sd2=0.286, size2=10000) #Mimics single distribution\n",
    "\n",
    "simulated_data = pd.DataFrame(data=dict_random_tau_data) #Fit in a dataframe\n",
    "simulated_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I purposefully changed two distributions in the data to simulate potential situations: first I inverted the *low* and *high* distributions for the `CTX_RH_PRECENTRAL_SUVR`, and I also forced a single distribution for the `CTX_RH_POSTCENTRAL_SUVR`. It is simulated data: it's up to you to try and simulate a problem you want to check using the spatial extent.\n",
    "\n",
    "From there you can simply merge this data to the IDs of the PREVENT-AD (or your own IDs) and you have a fully simulated dataset!\n",
    "\n",
    "```{admonition} Advanced topics: Going further than two components\n",
    "Once you understand the concepts behind the spatial extent, you can run with it and create your own. For instance, what if your data had not 1, not 2, but 3 distributions? You could think of deriving multiple sets of thresholds (low to medium, medium to high for instance).\n",
    "\n",
    "Accordingly, you can use the examples on this page to build new simulated data fitting your needs, on which you can test the functions.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature - Abnormality in PET data\n",
    "\n",
    "`sihnpy` regroups tools meant to serve the neuroimaging field as broadly as possible. As such, while I talk a bit about the literature behind each module, I don't really go in depth behind the reasoning of some of the module but rather provide ressources and references meant to be used to go further.\n",
    "\n",
    "That said, I feel like learning a bit more about the Alzheimer's literature on the topic may help guide you in terms of **choosing the right methodology and thresholds** for your own data, whatever population you apply it to, so I created this extra section, discussing a bit on the literature of Alzheimer's and also discusses how to choose your thresholds.\n",
    "\n",
    "Studies of pathology in Alzheimer's disease is usually focused on the two main pathological hallmarks: amyloid and tau pathology. Some studies have used Gaussian mixture modelling before to generate thresholds to determine what is **\"normal\"** or **\"abnormal\"**. Using amyloid pathology for instance, authors have generally opted for values above 90th percentile of belonging to the **\"normal\"** distribution.[^Ozlen_2022] [^Mormino_2014] [^Villeneuve_2015] This is a somewhat more liberal threshold, but goes with the rationale that once the probability that a person belongs to the \"normal\" distribution drops, we become uncertain of whether the person can still be considered **\"normal\"**. See annotated graph below:\n",
    "\n",
    "INSERT ENTORHINAL GRAPH\n",
    "\n",
    "To use this type of threshold in `sihnpy`, you simply have to set the \"abnormality\" threshold to `0.1` (i.e., the opposite of 90% probability of belonging to the \"normal\" distribution is 10% of belonging to the \"abnormal\" distribution). \n",
    "\n",
    "A different philosophy to set these thresholds is to directly go with the probability of belonging to the **\"abnormal\"** distribution (i.e., the philosophy behind `sihnpy`'s `spatial_extent` module). [^Vogel_2020] [^Franzmeier_2020] This usually yields slightly more conservative thresholds, as probability of abnormality increases with PET uptake. See annotated graph below:\n",
    "\n",
    "INSERT ENTORHINAL GRAPH\n",
    "\n",
    "`sihnpy` is already set so that any probability thresholds given reflect the probability of belonging to the \"abnormal\" distribution. While previous work used this method, [^Vogel_2020] [^Franzmeier_2020] they did not set thresholds to be used. In our recent work, we opted for 50% probability of belonging to the \"abnormal\" distribution, but we found similar results using a conservative threshold at 90%. [^Stonge_2023]\n",
    "\n",
    "So what should you choose?\n",
    "\n",
    "That really depends on whether you need a more liberal/sensitive threshold or a more conservative/specific threshold. You also have to be mindful of the overlap between the two distribution. In some cases, the two distributions will overlap quite a lot, meaning that the probabilities may yield thresholds of very low values. See example below:\n",
    "\n",
    "INSERT OVERLAP DISTRIB IMAGE\n",
    "\n",
    "**My recommendation is to choose 1 main threshold and 2-3 other thresholds to replicate your results**. That way you can make sure that the thresholds set make sense with your data. **My other recommendation is to always look at the data to ensure that the thresholds you derive are biologically plausible**.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Need for info? Make sure to go read these sources:\n",
    "\n",
    "[^Ozlen_2022]: REF\n",
    "[^Mormino_2014]: REF\n",
    "[^Villeneuve_2015]: REF\n",
    "[^Vogel_2020]: REF\n",
    "[^Franzmeier_2020]: REF\n",
    "[^Stonge_2023]: REF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sihnpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
